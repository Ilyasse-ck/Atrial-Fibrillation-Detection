{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7763d3ca",
   "metadata": {},
   "source": [
    "# Dynamic training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de23b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ecg_labeling as lab\n",
    "import pandas as pd\n",
    "import xmltodict\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import save\n",
    "from numpy import load\n",
    "from numpy import asarray\n",
    "import keras\n",
    "import numpy as np\n",
    "from numpy import load\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.layers import Dense, Convolution1D, Flatten, Convolution2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.regularizers import l1\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Dense, Dropout, Activation, BatchNormalization, Add\n",
    "from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPool1D, ZeroPadding1D, LSTM, Bidirectional\n",
    "from keras.models import Sequential, Model\n",
    "from keras.utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import optimize\n",
    "from scipy.io import loadmat\n",
    "import os\n",
    "import seaborn as sns\n",
    "from numpy import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3b51ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters):\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    X_shortcut = X\n",
    "    \n",
    "    X =Conv1D(filters = 64, kernel_size = 1,activation='relu', strides = 1, padding = 'same')(X)\n",
    "    X=BatchNormalization()(X)\n",
    "    \n",
    "    X =Conv1D(filters = 64, kernel_size = 1,activation='relu', strides = 1, padding = 'same')(X)\n",
    "    X=BatchNormalization()(X)\n",
    "    \n",
    "    X = Conv1D(filters = 64, kernel_size = 1, activation='relu', strides = 1, padding = 'valid')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    \n",
    "    X = Conv1D(filters = F2, kernel_size = f, activation='relu', strides = 1, padding = 'same')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "\n",
    "    X = Conv1D(filters = F3, kernel_size = 1, activation='relu', strides = 1, padding = 'valid')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    \n",
    "    \n",
    "    X = Add()([X,X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X\n",
    "\n",
    "def convolutional_block(X, f, filters, s = 2):\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    X_shortcut = X\n",
    "\n",
    "    X = Conv1D(F1, 1, activation='relu', strides = s)(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    \n",
    "    X = Conv1D(F2, f, activation='relu', strides = 1,padding = 'same')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    \n",
    "    X = Conv1D(F3, 1, strides = 1)(X)\n",
    "    X = BatchNormalization()(X)\n",
    "\n",
    "    X_shortcut = Conv1D(F3, 1, strides = s)(X_shortcut)\n",
    "    X_shortcut = BatchNormalization()(X_shortcut)\n",
    "    \n",
    "    X = Add()([X,X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X\n",
    "\n",
    "def ResNet50(input_shape):\n",
    "    \n",
    "    X_input=Input(input_shape)\n",
    "    \n",
    "    X = ZeroPadding1D(3)(X_input)\n",
    "    \n",
    "    X = Conv1D(filters = 64, kernel_size = 7, padding = 'same')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPool1D(pool_size=3, strides=2, padding='same')(X)\n",
    "    \n",
    "    X = Conv1D(filters = 64, kernel_size = 1, padding = 'same')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X = MaxPool1D(pool_size=7, strides=2, padding='same')(X)\n",
    "    \n",
    "    X = GlobalAveragePooling1D()(X)\n",
    "    X = Dense(27,activation='sigmoid')(X)\n",
    "    \n",
    "    \n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    X = ZeroPadding1D(3)(X_input)\n",
    "    \n",
    "    X = Conv1D(64, 7, strides = 2)(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPool1D(pool_size=2, strides=2, padding='same')(X)\n",
    "\n",
    "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], s = 1)\n",
    "    X = identity_block(X, 3, [64, 64, 256])\n",
    "    X = identity_block(X, 3, [64, 64, 256])\n",
    "\n",
    "    X = convolutional_block(X, f = 3, filters = [128,128,512], s = 2)\n",
    "    X = identity_block(X, 3, [128,128,512])\n",
    "    X = identity_block(X, 3, [128,128,512])\n",
    "    X = identity_block(X, 3, [128,128,512])\n",
    "    \n",
    "\n",
    "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], s = 2)\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    \n",
    "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], s = 2)\n",
    "    X = identity_block(X, 3, [512, 512, 2048])\n",
    "    X = identity_block(X, 3, [512, 512, 2048])\n",
    "\n",
    "    X = MaxPool1D(pool_size=2, strides=2, padding='same')(X)\n",
    "    \n",
    "    X = GlobalAveragePooling1D()(X)\n",
    "    X = Dense(6,activation='sigmoid')(X)\n",
    "    \n",
    "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a51359a",
   "metadata": {},
   "outputs": [],
   "source": [
    "resNet50_model = ResNet50(input_shape = (5000,12))\n",
    "resNet50_model.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics=[tf.keras.metrics.CategoricalAccuracy(\n",
    "        name='accuracy', dtype=None),tf.keras.metrics.Recall(name='Recall'),tf.keras.metrics.Precision(name='Precision'), \n",
    "                    tf.keras.metrics.AUC(\n",
    "        num_thresholds=200,\n",
    "        curve=\"ROC\",\n",
    "        summation_method=\"interpolation\",\n",
    "        name=\"AUC\",\n",
    "        dtype=None,\n",
    "        thresholds=None,\n",
    "        multi_label=True,\n",
    "        label_weights=None,\n",
    "    )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b11a787",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_array=np.array([i for i in range(27000)])\n",
    "def shuffle_batch_generator(batch_size, gen_x,gen_y): \n",
    "    np.random.shuffle(order_array)\n",
    "    batch_features = np.zeros((batch_size,5000, 12))\n",
    "    batch_labels = np.zeros((batch_size,6)) #drop undef class\n",
    "    while True:\n",
    "        for i in range(batch_size):\n",
    "\n",
    "            batch_features[i] = next(gen_x)\n",
    "            batch_labels[i] = next(gen_y)\n",
    "            \n",
    "        yield batch_features, batch_labels\n",
    "\n",
    "def generate_y_shuffle(y_train):\n",
    "    while True:\n",
    "        for i in order_array:\n",
    "            y_shuffled = y_train[i]\n",
    "            yield y_shuffled\n",
    "\n",
    "def generate_X_shuffle(X_train):\n",
    "    while True:\n",
    "        for i in order_array:\n",
    "                #if filepath.endswith(\".mat\"):\n",
    "                    X_train_new=load(r\"C:\\Users\\ilyas\\Documents\\Altao_ecg_xml\\ECG_data\\DATA_training\"+'/'+str(X_train[i]),allow_pickle=True)\n",
    "                    X_train_new = X_train_new.reshape(5000,12)\n",
    "                    yield X_train_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a582e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 10\n",
    "resNet50_model.fit(x=shuffle_batch_generator(batch_size=batchsize, gen_x=generate_X_shuffle(ecg_filenames), gen_y=generate_y_shuffle(y_train)), epochs=20, steps_per_epoch=(len(order_array)/(batchsize*10)), validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f4b680",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Article on batch generators: https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
