{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "034ee4d3",
   "metadata": {},
   "source": [
    "# ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b05d9f",
   "metadata": {},
   "source": [
    "## 1. Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1663c4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import save\n",
    "from numpy import load\n",
    "from numpy import asarray\n",
    "import keras\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.layers import Dense, Convolution1D, Flatten, Convolution2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.regularizers import l1\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Dense, Dropout, Activation, BatchNormalization, Add\n",
    "from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPool1D, ZeroPadding1D, LSTM, Bidirectional\n",
    "from keras.models import Sequential, Model\n",
    "from keras.utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import optimize\n",
    "from scipy.io import loadmat\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.layers import concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e718aa2",
   "metadata": {},
   "source": [
    "## 2. Data importing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c3340c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the training and test data from 3. Data set generation\n",
    "#X_train\n",
    "#y_train\n",
    "#X_test\n",
    "#y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1deae84b",
   "metadata": {},
   "source": [
    "## 3. ResNet50 structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14a00aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters):\n",
    "    \"\"\"\n",
    "    Implements an identity block for ResNet.\n",
    "\n",
    "    Args:\n",
    "        X (Tensor): Input tensor to the block.\n",
    "        f (int): Kernel size for the middle convolutional layer.\n",
    "        filters (list of int): List containing the number of filters for each convolutional layer (F1, F2, F3).\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Output of the identity block.\n",
    "    \"\"\"\n",
    "    F1, F2, F3 = filters  # Unpack filter sizes for each layer\n",
    "\n",
    "    X_shortcut = X  # Save the input tensor for the shortcut connection\n",
    "\n",
    "    # First convolutional layer\n",
    "    X = Conv1D(filters=64, kernel_size=5, activation='relu', strides=1, padding='same')(X)\n",
    "    X = BatchNormalization()(X)  # Normalize activations\n",
    "\n",
    "    # Second convolutional layer\n",
    "    X = Conv1D(filters=64, kernel_size=5, activation='relu', strides=1, padding='same')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "\n",
    "    # Third convolutional layer\n",
    "    X = Conv1D(filters=64, kernel_size=5, activation='relu', strides=1, padding='same')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "\n",
    "    # Fourth convolutional layer with `f` kernel size\n",
    "    X = Conv1D(filters=F2, kernel_size=f, activation='relu', strides=1, padding='same')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "\n",
    "    # Fifth convolutional layer with 1x1 kernel\n",
    "    X = Conv1D(filters=F3, kernel_size=1, activation='relu', strides=1, padding='same')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "\n",
    "    # Add the shortcut connection and apply ReLU activation\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "def convolutional_block(X, f, filters, s=2):\n",
    "    \"\"\"\n",
    "    Implements a convolutional block for ResNet, which includes a downsampling shortcut connection.\n",
    "\n",
    "    Args:\n",
    "        X (Tensor): Input tensor to the block.\n",
    "        f (int): Kernel size for the middle convolutional layer.\n",
    "        filters (list of int): List containing the number of filters for each convolutional layer (F1, F2, F3).\n",
    "        s (int): Stride for the first convolutional layer in the block.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Output of the convolutional block.\n",
    "    \"\"\"\n",
    "    F1, F2, F3 = filters  # Unpack filter sizes for each layer\n",
    "\n",
    "    X_shortcut = X  # Save the input tensor for the shortcut connection\n",
    "\n",
    "    # First convolutional layer with downsampling\n",
    "    X = Conv1D(F1, 1, activation='relu', strides=s)(X)\n",
    "    X = BatchNormalization()(X)\n",
    "\n",
    "    # Second convolutional layer\n",
    "    X = Conv1D(F2, f, activation='relu', strides=1, padding='same')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "\n",
    "    # Third convolutional layer\n",
    "    X = Conv1D(F3, 1, strides=1)(X)\n",
    "    X = BatchNormalization()(X)\n",
    "\n",
    "    # Shortcut connection with downsampling\n",
    "    X_shortcut = Conv1D(F3, 1, strides=s)(X_shortcut)\n",
    "    X_shortcut = BatchNormalization()(X_shortcut)\n",
    "\n",
    "    # Add the shortcut connection and apply ReLU activation\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "def ResNet50(input_shape):\n",
    "    \"\"\"\n",
    "    Builds the ResNet50 architecture.\n",
    "\n",
    "    Args:\n",
    "        input_shape (tuple): Shape of the input tensor (time steps, features).\n",
    "\n",
    "    Returns:\n",
    "        keras.Model: A Keras model instance representing the ResNet50 architecture.\n",
    "    \"\"\"\n",
    "    X_input = Input(input_shape)  # Define input tensor\n",
    "\n",
    "    # Initial convolutional layer and max pooling\n",
    "    X = ZeroPadding1D(3)(X_input)\n",
    "    X = Conv1D(64, 7, strides=2)(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPool1D(pool_size=2, strides=2, padding='same')(X)\n",
    "\n",
    "    # First convolutional block and identity blocks\n",
    "    X = convolutional_block(X, f=3, filters=[64, 64, 256], s=1)\n",
    "    X = identity_block(X, 3, [64, 64, 256])\n",
    "    X = identity_block(X, 3, [64, 64, 256])\n",
    "\n",
    "    # Second convolutional block and identity blocks\n",
    "    X = convolutional_block(X, f=3, filters=[128, 128, 512], s=2)\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "\n",
    "    # Third convolutional block and identity blocks\n",
    "    X = convolutional_block(X, f=3, filters=[256, 256, 1024], s=2)\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "\n",
    "    # Fourth convolutional block and identity blocks\n",
    "    X = convolutional_block(X, f=3, filters=[512, 512, 2048], s=2)\n",
    "    X = identity_block(X, 3, [512, 512, 2048])\n",
    "    X = identity_block(X, 3, [512, 512, 2048])\n",
    "    X = identity_block(X, 3, [512, 512, 2048])\n",
    "\n",
    "    # Final pooling and output layer\n",
    "    X = MaxPool1D(pool_size=2, strides=2, padding='same')(X)\n",
    "    X = GlobalAveragePooling1D()(X)\n",
    "    X = Dense(2, activation='sigmoid')(X)  # Output layer with 2 units for binary classification\n",
    "\n",
    "    model = Model(inputs=X_input, outputs=X, name='ResNet50')\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c77e26d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the ResNet50 model with the specified input shape\n",
    "# The model is designed for 1D inputs with a sequence length of 5000 and 12 features per time step.\n",
    "model_new = ResNet50(input_shape=(5000, 12))\n",
    "\n",
    "# Compile the model with the following configurations:\n",
    "# - Loss function: Binary Crossentropy for binary classification tasks.\n",
    "# - Optimizer: Adam optimizer with a learning rate of 0.01 for gradient-based optimization.\n",
    "# - Metrics: \n",
    "#   - BinaryAccuracy: Calculates accuracy based on a threshold (default 0.5).\n",
    "#   - Recall: Measures the proportion of correctly predicted positive samples.\n",
    "#   - Precision: Measures the proportion of true positives among all predicted positives.\n",
    "model_new.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "    metrics=[\n",
    "        tf.keras.metrics.BinaryAccuracy(name='accuracy', threshold=0.5),\n",
    "        tf.keras.metrics.Recall(name='Recall'),\n",
    "        tf.keras.metrics.Precision(name='Precision')\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2d79bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "batchsize = 20 \n",
    "model_new.fit(x=X_train, y=y_train, validation_data=(X_test,Y_test),epochs=150)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
