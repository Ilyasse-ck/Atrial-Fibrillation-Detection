{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "034ee4d3",
   "metadata": {},
   "source": [
    "# ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b05d9f",
   "metadata": {},
   "source": [
    "## 1. Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1663c4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import save\n",
    "from numpy import load\n",
    "from numpy import asarray\n",
    "import keras\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.layers import Dense, Convolution1D, Flatten, Convolution2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.regularizers import l1\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Dense, Dropout, Activation, BatchNormalization, Add\n",
    "from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPool1D, ZeroPadding1D, LSTM, Bidirectional\n",
    "from keras.models import Sequential, Model\n",
    "from keras.utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import optimize\n",
    "from scipy.io import loadmat\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.layers import concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e718aa2",
   "metadata": {},
   "source": [
    "## 2. Data importing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c3340c",
   "metadata": {},
   "outputs": [],
   "source": [
    """Load the training and test data from 3. Data set generation""\n",
    "#X_train\n",
    "#y_train\n",
    "#X_test\n",
    "#y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1deae84b",
   "metadata": {},
   "source": [
    "## 3. ResNet50 structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14a00aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters):\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    X_shortcut = X\n",
    "    \n",
    "    X =Conv1D(filters = 64, kernel_size = 5,activation='relu', strides = 1, padding = 'same')(X)\n",
    "    X=BatchNormalization()(X)\n",
    "    \n",
    "    X =Conv1D(filters = 64, kernel_size = 5,activation='relu', strides = 1, padding = 'same')(X)\n",
    "    X=BatchNormalization()(X)\n",
    "    \n",
    "    X = Conv1D(filters = 64, kernel_size = 5, activation='relu', strides = 1, padding = 'same')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    \n",
    "    X = Conv1D(filters = F2, kernel_size = f, activation='relu', strides = 1, padding = 'same')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "\n",
    "    X = Conv1D(filters = F3, kernel_size = 1, activation='relu', strides = 1, padding = 'same')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    \n",
    "    \n",
    "    X = Add()([X,X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X\n",
    "\n",
    "def convolutional_block(X, f, filters, s = 2):\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    X_shortcut = X\n",
    "\n",
    "    X = Conv1D(F1, 1, activation='relu', strides = s)(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    \n",
    "    X = Conv1D(F2, f, activation='relu', strides = 1,padding = 'same')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    \n",
    "    X = Conv1D(F3, 1, strides = 1)(X)\n",
    "    X = BatchNormalization()(X)\n",
    "\n",
    "    X_shortcut = Conv1D(F3, 1, strides = s)(X_shortcut)\n",
    "    X_shortcut = BatchNormalization()(X_shortcut)\n",
    "    \n",
    "    X = Add()([X,X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X\n",
    "\n",
    "def ResNet50(input_shape):\n",
    "    \n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    X = ZeroPadding1D(3)(X_input)\n",
    "    \n",
    "    X = Conv1D(64, 7, strides = 2)(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPool1D(pool_size=2, strides=2, padding='same')(X)\n",
    "\n",
    "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], s = 1)\n",
    "    X = identity_block(X, 3, [64, 64, 256])\n",
    "    X = identity_block(X, 3, [64, 64, 256])\n",
    "\n",
    "    X = convolutional_block(X, f = 3, filters = [128,128,512], s = 2)\n",
    "    X = identity_block(X, 3, [128,128,512])\n",
    "    X = identity_block(X, 3, [128,128,512])\n",
    "    X = identity_block(X, 3, [128,128,512])\n",
    "    \n",
    "    X = convolutional_block(X, f = 3, filters = [256,256,1024], s = 2)\n",
    "    X = identity_block(X, 3, [256,256,1024])\n",
    "    X = identity_block(X, 3, [256,256,1024])\n",
    "    X = identity_block(X, 3, [256,256,1024])\n",
    "    \n",
    "    X = convolutional_block(X, f = 3, filters = [512,512,2048], s = 2)\n",
    "    X = identity_block(X, 3, [512,512,2048])\n",
    "    X = identity_block(X, 3, [512,512,2048])\n",
    "    X = identity_block(X, 3, [512,512,2048])\n",
    "    \n",
    "    X = MaxPool1D(pool_size=2, strides=2, padding='same')(X)\n",
    "    \n",
    "    X = GlobalAveragePooling1D()(X)\n",
    "    X = Dense(2,activation='sigmoid')(X)\n",
    "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c77e26d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new=ResNet50(input_shape = (5000,12))\n",
    "model_new.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), metrics=[tf.keras.metrics.BinaryAccuracy(\n",
    "        name='accuracy', dtype=None, threshold=0.5),tf.keras.metrics.Recall(name='Recall'),tf.keras.metrics.Precision(name='Precision')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2d79bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 20 \n",
    "model_new.fit(x=X_train, y=y_train, validation_data=(X_test,Y_test),epochs=150)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
